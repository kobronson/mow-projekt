% najpierw jest wstep, załączenie potrzebnych pakietów itp.
\documentclass[a4paper, 10pt]{article}

%polskie znaki
\usepackage[polish]{babel}
\usepackage[utf8]{inputenc}
\usepackage[OT4]{fontenc}

%wieksze mozliwosci zmiany wygladu strony, pakiet do wstawiania linków
\usepackage{geometry}
\usepackage{ulem}
\RequirePackage{url}

% ladne wciecia akapitow i odstepy, mozna wykasowac wedle uznania;)
\setlength{\parindent}{0cm}
\setlength{\parskip}{3mm plus1mm minus1mm}

%mniejsze marginesy
\geometry{verbose,a4paper,tmargin=2.4cm,bmargin=2.4cm,lmargin=2.4cm,rmargin=2.4cm}
\usepackage{graphicx} % wstawianie obrazkow


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{{\bf {Metody odkrywania wiedzy }} \\ {\large Dokumentacja wstępna projektu}}
\date{\today}
\author{Dominika Sawicka \\Filip Nabrdalik}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\bibliographystyle{alpha}
%%%%%%%
\null  % Empty line
\nointerlineskip  % No skip for prev line
\vfill
\let\snewpage \newpage
\let\newpage \relax
\maketitle %wstawienie tytulu, daty i autora
\let \newpage \snewpage
\vfill
\break % page break
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents

\newpage


% Przydatne linki:
% 	http://www.ke.tu-darmstadt.de/lehre/archiv/ss12/web-mining/wm-tm.pdf
%	http://www.dis.uniroma1.it/~leon/didattica/webir/IR11.pdf
%	http://cran.r-project.org/web/packages/tm/tm.pdf
%	https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Classification
%	http://www.statsoft.com.pl/textbook/stathome_stat.html?http%3A%2F%2Fwww.statsoft.com.pl%2Ftextbook%2Fstnaiveb.html




\section{Treść zadania}

{\bf{Zadanie 17}}

Proste algorytmy klasyfikacji tekstu (TF-IDF, naiwny klasyfikator Bayesowski, kNN). Porównania ze standardowymi algorytmami klasyfikacji dostępnymi w R.



\section{Szczegółowa interpretacja tematu projektu}

Celem projektu jest implementacja w języku R oraz eksperymentalna ocena efektywności trzech algorytmów klasyfikacji tekstu:
\begin{itemize}
\item TF-IDF 
\item kNN
\item Naiwny klasyfikator Bayesowski
\end{itemize}
Eksperymenty projektowe będą obejmowały porównanie autorskich wersji algorytmów z ich implementacjami dostępnymi w pakiecie R, a także
zaawansowanymi algorytmami klasyfikacji tekstu. Do badań zostaną użyte zbiory danych tekstowych z repozytorium UCI \cite{website:uci}.

\subsection{Wstęp}
% https://www.usenix.org/legacy/event/sec02/full_papers/liao/liao_html/node4.html

Klasyfikacją tekstu nazywamy proces przyporządkowania tekstów do określonych kategorii w oparciu o ich zawartość. 

Pierwszym zadaniem w klasyfikacji tekstu jest przekształcenie dokumentów tekstowych, będących zwykle ciągami znaków, do postaci odpowiedniej do zastosowania algorytmów uczenia i klasyfikacji.
Najczęściej stosowana jest reprezentacja tekstu jako modelu przestrzeni wektorowej. W tym modelu każdy dokument reprezentowany jest jako wektor słów. Zbiór tekstów przechowywany jest w macierzy ${A}$, w której kolumnach umieszczone są poszczególne słowa a wierszach przygotowywane do klasyfikacji teksty. Każdy element macierzy odpowiada wystąpieniu słowa w tekście, np. ${A = (a_{ij})}$, gdzie $(a_{ij})$ jest wagą słowa $i$ w dokumencie $j$. 

Istnieje kilka sposobów określania wagi $i$. W dalszej części dokumentacji przedstawiono wybrane z nich.

\section{Wykorzystywane algorytmy}
%rozmumiem, że opisywać dokładnie mamy tylko te, które implementujemy 

\subsection{TF-IDF}

TF-IDF (ang. TF – term frequency, IDF – inverse document frequency) informuje o częstości wystąpienia termów uwzględniając 
wyważenie znaczenia lokalnego termu oraz jego znaczeniu w kolekcji dokumentów. W algorytmie TF-IDF każdy dokument reprezentowany
jest przez wektor zawierający wagi słów występujących w dokumencie. Wartość TF-IDF (1):


\begin{equation}
\mathrm{(tf\mbox{-}idf)_{i,j}} = \mathrm{tf_{i,j}} \times  \mathrm{idf_{i}}
\end{equation}

"Term frequency" (2), gdzie $n_{i,j}$ to liczbą wystąpień termu ($t_{i}$) w dokumencie $d_{j}$, a mianownik jest sumą liczby wystąpień wszystkich termów w dokumencie $d_{j}$:
 
\begin{equation}
\mathrm{tf_{i,j}} = \frac{n_{i,j}}{\sum_k n_{k,j}}
\end{equation}

"Inverse document frequency" (3), gdzie $|D|$ to liczba dokumentów, a $|\{d : t_{i} \in d\}|$ reprezentuje zbiór dokumentów zawierających
jedno wystąpienie danego termu:

\begin{equation}
\mathrm{idf_{i}} =  \log \frac{|D|}{|\{d: t_{i} \in d\}|}
\end{equation}

Algorytm stosowany jest w systemach anty plagiatowych do oceny podobieństwa dokumentów, w wyszukiwarkach internetowych oraz systemach
antyspamowych, gdzie potrzebna jest klasyfikacja tekstu.

\subsection{kNN}

Algorytm kNN (ang. k-nearest neighbors algorithm) pozwala sklasyfikować nieznany dokument $X$  poprzez uszeregowanie sąsiadów dokumentu spośród wektorów treningowych i wykorzystanie przynależności do klas $k$ najbardziej podobnych sąsiadów do przewidzenia klasy nieznanego dokumentu. Klasom sąsiadów przypisuje się wagi w zależności od podobieństwa każdego sąsiada do $X$ mierzonego odległością euklidesową lub wartością cosinusa kąta pomiędzy opisującymi je wektorami ważonych atrybutów. Podobieństwo mierzone wartością cosinusa definiuje następujący wzór:

\begin{equation}
\mathrm{sim(X, D_{j}) = \frac{
\sum_{ t_{i} \in (x\cap D_{j})
  }x_{i} \times d_{ij}}{||X||_{2} \times ||D_{j}||_{2}}}
\end{equation}

gdzie:\\
$X$ - testowany dokument reprezentowany w postaci wektora\\
$D_{j}$ - $j$-ty dokument treningowy\\
$t_{i}$ - słowo wspólne dla $X$ i $D_{j}$\\
$x_{i}$ - waga słowa $t_{i}$ w $X$\\
$d_{ij}$ - waga słowa $t_{i}$ w dokumencie $D_{j}$\\
$||X||_{2} = \sqrt{{x_{1}}^{2} + {x_{2}}^{2} + {x_{3}}^{2} + ...}$ - norma X\\
$||D_{j}||_{2}$ - norma $D_{j}$\\



%http://www.mimuw.edu.pl/~krzadca/zadanie-kNN.html

\subsection{Naiwny klasyfikator Bayesowski}

Naiwny klasyfikator bayesowski (1) jest to prosty klasyfikator probabilistyczny, którego w trybie "uczenia z nadzorem" można skutecznie użyć do 
klasyfikacji dokumentów.

\begin{equation}
p(C \vert F_1,\dots,F_n) = \frac{1}{Z}  p(C) \prod_{i=1}^n p(F_i \vert C)
\end{equation}

Powyższego wzoru (4), wynikającego z tw. Bayesa, można użyć do zaklasyfikowania dokumentu do danego zbioru lub klasy jeśli spełniony jest warunek (6).
\begin{equation}
\ln{p(S\vert D)\over p(\neg S\vert D)}=\ln{p(S)\over p(\neg S)}+\sum_i \ln{p(w_i\vert S)\over p(w_i\vert\neg S))}
\end{equation}
\begin{equation}
\ln{p(S\vert D)\over p(\neg S\vert D)} > 0
\end{equation}

Gdzie: $S$ - klasa dokumentu, $D$ - dokumenty, $w_i$ - pojedynczy term lub słowo.




\subsection{Algorytmy z pakietu R}

Do porównania autorskich implementacji algorytmów zostały wybrane następujące wersje z pakietów R. Poniżej 
nazwy pakietów wraz z krótkim opisem algorytmu, jesli nie został opisany w poprzednich podrozdziałach.

\begin{itemize}
\item{kNN [{\it RWeka}],} 
\item{Naiwny klasyfikator Bayesowski [{\it e1071}],}
\item{SVM [{\it e1071}] (ang. Support Vector Machine), klasyfikator którego nauka ma na calu wyznaczenie hiperpłaszczyzny rozdzielającej z maksymalnym marginesem przykłady należące do dwóch klas. Algorytm wykorzystywany do klasyfikacji stron www, obrazów oraz protein,} 
\item{Random forest [{\it RTextTools}], algorytm oparty o tworzenie lasów drzew decyzyjnych podczas nauki do klasyfikacji.} 
\end{itemize}

Wiekszość powyższych algorytmów jest dostępnych w zbiorczym pakiecie {\it RTextTools}. Jest to wstępna lista algorytmów z pakietów R do testowania i może ona ulec zmianie w dalszych fazach projektu.

%tutaj troszke o algorytmach dostepnych w R (te z ktorymi bedziemy porownywac)
%dobry link https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Classification
%trzeba bedzie porównac te nasze z zaimplementowanymi w R + z jakims bardziej zaawansowanym dostepnym w R np. SVM

\section{Plan eksperymentów}
\subsection{Pytania, na które będzie poszukiwana odpowiedź}

\begin{itemize}
\item{Który z testowanych algorytmów klasyfikacji jest najlepszy w kontekście badanych parametrów?}
\item{Jak rozmiar danych uczących wpływa na poprawę skuteczności modeli?}
\item{Czy na podstawie przeprowadzonych testów możliwe jest wyłonienie bezwzględnie najlepszego algorytmu?}
\end{itemize}

\subsection{Charakterystyka wykorzystywanych zbiorów danych}

Do celów testowych zodstały wybrane następujace zbiory danych dostępne w repozystorium UCI.


\begin{itemize}
\item{SMS Spam \url{http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection} \\ kolekacja ponad 5000 wiadomosci SMS w jezyku angielskim, z których ok. 1000 zawiera spam. Dane zebrane są w jednym pliku, każda wiadomość znajduje się oddzielnym wierzu i 
jest poprzedzona informacja do jakiego typu należy. Dane nie zostały poddane obróbce. Konieczne będzie przetworzenie danych przed ich klasyfikacją.} 
\item{SpamBase (\url{http://archive.ics.uci.edu/ml/datasets/Spambase}) \\ zbiór przykładów wygenerowany z 4601 wiadomosci email z których ok. 40\% została zaklasyfikowana jako spam. Atrybuty zostały otrzymane z 48 najsczęściej wystapuących słów, 6 ze znaków specjalnych i interpunkcyjnych oraz 3 z ilości nieprzerwanych ciągów wielkich liter.  W Każdy wiersz zawiera następuące atrybuty: 54 całkowitoliczbowwych [1,100] procent występowania słowa lub znaku w danej wiadomości i 3 całkowitoliczbowe reprezentujące ilośc wielkich liter oraz średnia i maksymalna długość łańcuchów wielkich liter w danej wiadomości email. Ostatni atrybut w zbiorze danych wskazuje czy dana wiadomość jest spamem. Dane nie wymagaja dalszej obróbki. }

\end{itemize}


	%Proponuje takie zbiory danych, ale to jeszcze do zastanowienia:
	%http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection
	%http://archive.ics.uci.edu/ml/datasets/DBWorld+e-mails
	%http://archive.ics.uci.edu/ml/datasets/Legal+Case+Reports

\subsection{Parametry algorytmów, których wpływ na wyniki będzie badany}

\begin{itemize}
\item{liczebność zbioru uczącego}
\item{liczba $k$ sąsiadów w algorytmie kNN}
\item{%jakieś parametry tych 2 dodatkowych algorytmów z R-a??
}
\end{itemize}

%parametr k z kNN

\subsection{Sposób oceny jakości modeli}

Jakość modeli będzie oceniana na podstawie wartości \textit{recall} i \textit{precision} oraz czasu potrzebnego na przeprowadzenie klasyfikacji.

\begin{equation}
recall = \frac{TP}{TP + FN}
\end{equation}

\begin{equation}
precision = \frac{TP}{FP + TP}
\end{equation}

gdzie:\\
$TP$ (true positive) - wiadomości będące SPAMem, zaklasyfikowane jako SPAM\\
$FP$ (false positive) - wiadomości będące SPAMem, nie zaklasyfikowane jako SPAM\\
$FN$ (false negative) - wiadomości nie będące SPAMem, zaklasyfikowane jako SPAM\\

Wartość \textit{recall} mówi o tym, ile obiektów z danej klasy rozpoznaje model, natomiast \textit{precision} jest miarą tego dokładności klasyfikacji w obrębie rozpoznanej klasy.

%BIBLIOGRAFIA
\nocite{*}
\bibliography{bibliografia}


\end{document}


