% najpierw jest wstep, załączenie potrzebnych pakietów itp.
\documentclass[a4paper, 10pt]{article}

%polskie znaki
\usepackage[polish]{babel}
\usepackage[utf8]{inputenc}
\usepackage[OT4]{fontenc}

%wieksze mozliwosci zmiany wygladu strony, pakiet do wstawiania linków
\usepackage{geometry}
\usepackage{ulem}
\RequirePackage{url}

% ladne wciecia akapitow i odstepy, mozna wykasowac wedle uznania;)
\setlength{\parindent}{0cm}
\setlength{\parskip}{3mm plus1mm minus1mm}

%mniejsze marginesy
\geometry{verbose,a4paper,tmargin=2.4cm,bmargin=2.4cm,lmargin=2.4cm,rmargin=2.4cm}
\usepackage{graphicx} % wstawianie obrazkow


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{{\bf {Metody odkrywania wiedzy }} \\ {\large Dokumentacja wstępna projektu}}
\date{\today}
\author{Dominika Sawicka \\Filip Nabrdalik}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\bibliographystyle{alpha}
%%%%%%%
\null  % Empty line
\nointerlineskip  % No skip for prev line
\vfill
\let\snewpage \newpage
\let\newpage \relax
\maketitle %wstawienie tytulu, daty i autora
\let \newpage \snewpage
\vfill
\break % page break
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents

\newpage


% Przydatne linki:
% 	http://www.ke.tu-darmstadt.de/lehre/archiv/ss12/web-mining/wm-tm.pdf
%	http://www.dis.uniroma1.it/~leon/didattica/webir/IR11.pdf
%	http://cran.r-project.org/web/packages/tm/tm.pdf
%	https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Classification
%	http://www.statsoft.com.pl/textbook/stathome_stat.html?http%3A%2F%2Fwww.statsoft.com.pl%2Ftextbook%2Fstnaiveb.html




\section{Treść zadania}

{\bf{Zadanie 17}}

Proste algorytmy klasyfikacji tekstu (TF-IDF, naiwny klasyfikator Bayesowski, kNN). Porównania ze standardowymi algorytmami klasyfikacji dostępnymi w R.



\section{Szczegółowa interpretacja tematu projektu}

Celem projektu jest implementacja w języku R oraz eksperymentalna ocena efektywności trzech algorytmów klasyfikacji tekstu:
\begin{itemize}
\item TF-IDF 
\item kNN
\item Naiwny klasyfikator Bayesowski
\end{itemize}
Eksperymenty projektowe będą obejmowały porównanie autorskich wersji algorytmów z ich implementacjami dostępnymi w pakiecie R, a także
zaawansowanymi algorytmami klasyfikacji tekstu. Do badań zostaną użyte zbiory danych tekstowych z repozytorium UCI \cite{website:uci}.

\subsection{Wstęp}
% https://www.usenix.org/legacy/event/sec02/full_papers/liao/liao_html/node4.html

Klasyfikacją tekstu nazywamy proces przyporządkowania tekstów do określonych kategorii w oparciu o ich zawartość. 

Pierwszym zadaniem w klasyfikacji tekstu jest przekształcenie dokumentów tekstowych, będących zwykle ciągami znaków, do postaci odpowiedniej do zastosowania algorytmów uczenia i klasyfikacji.
Najczęściej stosowana jest reprezentacja tekstu jako modelu przestrzeni wektorowej. W tym modelu każdy dokument reprezentowany jest jako wektor słów. Zbiór tekstów przechowywany jest w macierzy ${A}$, w której kolumnach umieszczone są poszczególne słowa a wierszach przygotowywane do klasyfikacji teksty. Każdy element macierzy odpowiada wystąpieniu słowa w tekście, np. ${A = (a_{ij})}$, gdzie $(a_{ij})$ jest wagą słowa $i$ w dokumencie $j$. 

Istnieje kilka sposobów określania wagi $i$. W dalszej części dokumentacji przedstawiono wybrane z nich.

\section{Wykorzystywane algorytmy}
%rozmumiem, że opisywać dokładnie mamy tylko te, które implementujemy 

\subsection{TF-IDF}

TF-IDF (ang. TF – term frequency, IDF – inverse document frequency) informuje o częstosci wystąpienia termów uwzględniajac 
wyważenie znaczenia lokalnego termu oraz jego znaczeniu w kolekcji dokumentów. W algorytmie TF-IDF kazdy dokument reprezentowany
jest przez wektor zawierajacy wagi słow wystepujących w dokumencie. Wartość TF-IDF (1):


\begin{equation}
\mathrm{(tf\mbox{-}idf)_{i,j}} = \mathrm{tf_{i,j}} \times  \mathrm{idf_{i}}
\end{equation}

"Term frequency" (2), gdzie $n_{i,j}$ to liczbą wystąpień termu ($t_{i}$) w dokumencie $d_{j}$, a mianownik jest sumą liczby wystąpień wszystkich termów w dokumencie $d_{j}$:
 
\begin{equation}
\mathrm{tf_{i,j}} = \frac{n_{i,j}}{\sum_k n_{k,j}}
\end{equation}

"Inverse document frequency" (3), gdzie $|D|$ to liczba dokumentów, a $|\{d : t_{i} \in d\}|$ reprezentuje zbiór dokumentów zawierających
jedno wystąpienie danego termu:

\begin{equation}
\mathrm{idf_{i}} =  \log \frac{|D|}{|\{d: t_{i} \in d\}|}
\end{equation}

Algorytm stosowany jest w systemach antyplagiatowych do oceny podobieństwa dokumentów, w wyszukiwarkach internetowych oraz systemach
antyspamowych, gdzie potrzebna jest klasywikacja tekstu.

\subsection{kNN}

\subsection{Naiwny klasyfikator Bayesowski}

\subsection{Algorytmy z pakietu R}

%tutaj troszke o algorytmach dostepnych w R (te z ktorymi bedziemy porownywac)
%dobry link https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Classification
%trzeba bedzie porównac te nasze z zaimplementowanymi w R + z jakims bardziej zaawansowanym dostepnym w R np. SVM

\section{Plan eksperymentów}
\subsection{Pytania, na które będzie poszukiwana odpowiedź}
\subsection{Charakterystyka wykorzystywanych zbiorów danych}
	
	%Proponuje takie zbiory danych, ale to jeszcze do zastanowienia:
	%http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection
	%http://archive.ics.uci.edu/ml/datasets/DBWorld+e-mails
	%http://archive.ics.uci.edu/ml/datasets/Legal+Case+Reports


\subsection{Parametry algorytmów, których wpływ na wyniki będzie badany}
\subsection{Sposób oceny jakości modeli}

%BIBLIOGRAFIA
\nocite{*}
\bibliography{bibliografia}


\end{document}


